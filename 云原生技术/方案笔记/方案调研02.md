MCP

用于订阅推送的API，分为Source和Sink。

Source是资源提供方（server），资源变化了推送给订阅者（Pilot），Istio1.5之前这个角色是Galley或者自定义MCP Server。

1.6 之后为istiod

Sink 资源的订阅者（client），在Istio1.5之前这个角色是Pilot和Mixer，都是订阅Galley或者自定义MCP Server的资源。



![](https://gitee.com/laoliangcode/md-picture/raw/master/img/20210825141731.png)



@1 Sink为Pilot，Source为MCP Server

@2 Sink（Pilot）启动后会读取自己的配置文件映射到Pilot的本地，读mesh的文件source.config其中可以配置多个地址，即source的地址。

@3 sink与source之间通过gRPC进行连接

@4 sink根据与每个source地址建立watch操作，第一次请求req.version == nil （空），返回下发的最新版本，sink接受到后会有ack返回（直到req.version == mcp.version）

@5 mcp资源发生变化可以通过gRPC推送给sink



mcpserver demo：http://github.com/champly/mcpserver



### Pilot

Pilot 负责网格中流量管理以及控制面与数据面之间的配置下发，在Istio1.5之后合并了Gally、Citadel、Sidecar-inject和Pilot成为Istiod。

* 根据不同平台（kubernetes、console）获取一些资源（kubernetes 中使用Informer机制获取Node、Endpoint、Service、Pod的变化；1.6之后endpoint统一叫workload）
* 根据用户配置（CR、MCP推送、文件）触发推送流程
* 推送流程，会有一个事件记录变化的资源类型、根据变化的资源类型整理本地数据、根据变化的资源类型判断需要下发的xDS资源、构建xDS资源，下发连接的Sidecar



### xDS

Sidecar通过动态获取服务信息，对服务的发现API被称为xDS

**协议部分** （ADS）控制发送的顺序以及返回的确认数据

**数据部分** （CDS、EDS、RDS、SDS）



![image-20210825145618963](/Users/yongliang/Library/Application Support/typora-user-images/image-20210825145618963.png)



Serviceentries 会触发CDS、EDS、LDS、RDS的下发。



### MOSN

MOSN 是一款使用Go语言开发的网络代理软件，作为云原生的网络数据平面，旨在为服务提供多协议、模块化、智能化、安全的代理能力。MOSN是Modular Open Smart Network的简称。MOSN 可以与任何支持xDS API的Service Mesh集成，亦可以作为独立的四、七层负载均衡，API Gateway，云原生Ingress等使用。

配置文件

• mosn_config : MOSN 的配置信息

• listener : LDS

• routers : RDS

• cluster : CDS 和 EDS



**工作流程** 

MOSN启动之后会会有一个admin的接口，将维护在内存中的信息导出来mosn_config。以及连接哪个Pilot



主动请求过程：

首先连到Pilot之后，走的xDS协议，mosn首先为请求cluster（CDS资源），CDS资源下发下来之后如果为空，这个时候会请求LDS；如果CDS不为空会请求EDS资源，EDS请求到了会接着请求LDS，LDS请求到了其中包含一些route的名字，会请求RDS。



![image-20210825160013963](/Users/yongliang/Library/Application Support/typora-user-images/image-20210825160013963.png)



filter_chains



### 改造方案1

* 通过创建EnvoyFilter资源来给xDS资源打patch

* Envoy解析Dubbo协议中的Service和Method

* 根据路由策略配置把流量转发到对应的Provider

* 通过WASM扩展



问题：WASM的扩展可以通过Rust来编写



### 改造方案2

MOSN+Dubbo-go

* MOSN提供Subscribe、Unsubscribe、Publish、Unpublish服务
* SDK发送请求MOSN提供的服务
* MOSN通过Dubbo-go直接和注册中心连接



### 改造方案3

Istio + MOSN

* 数据面改造
* 控制面适配

备注：不会去动xDS的一些定义；数据面改造不改变主流程通过filter等扩展实现。



![image-20210825165514129](/Users/yongliang/Library/Application Support/typora-user-images/image-20210825165514129.png)



@1 consumer只需要调用本地的20811这个端口

@2 listener监听该端口-->router-->mosn get router->替换

@3 consumer.mosn的hosts中有provider的地址「provider adds:20882」

@4 consumer.mosn将请求发送到provider.mosn

@5 provider.mosn监听20882端口-->router-->cluster host（127.0.0.1:20880）

@6 请求发送到120.0.0.1:20880端口

@7 处理业务逻辑



### 控制面适配

* 对接注册中心
* 对接配置中心
* 连接多个集群
* 根据服务信息结合配置信息下发对应的集群的资源



![image-20210825173547321](/Users/yongliang/Library/Application Support/typora-user-images/image-20210825173547321.png)



图上有两个集群ClusterA和ClusterB，可以理解为蓝绿发布流量百分比；Adapter为多点自研；clusterA与ClusterB的Pilot没有交付



**注册流程** 

@1 provider1注册到mosn（provider1将mosn当成注册中心），注册端口为20880

@2 mosn拿到provider1的注册信息将端口改为20882，然后增加一些自己的标识比如蓝绿、机房等，并将信息注册到注册中心（比如：zookeeper）



**发现流程** 

@3 注册中心拿到注册信息会下发给Adapter，Adapter会连接注册中心和配置中心，同时Adapter同时会连接ClusterA和ClusterB的Pilot

@4 Pilot拿到信息放入内存（可以通过istioctl命令查看或者Pilot暴露的debug接口）

@5 Pilot通过xDS将注册信息下发给mosn（sideCar）



**调用流程** 

@6 consumer直接请求20881的端口到mosn上面，listner-->router-->cluster 的hosts

@7 如果provider2没有做mesh，则直接将20882注册到注册中心，consumer1拿到的地址为20882从而直接调用provider2；如果请求provider1直接端口20882到provider1的mosn

备注：Istio把serviceEntry和workload结合

@8 provider1 的mosn通过listener-->router-cluster的host路由到本地的的服务中。



**ServiceEntry：** 能够在 Istio 内部的服务注册表中加入额外的条目，从而让网格中自动发现的服务能够访问和路由到这些手工加入的服务。ServiceEntry描述了服务的属性（DNS 名称、VIP、端口、协议以及端点）。这类服务可能是网格外的 API，或者是处于网格内部但却不存在于平台的服务注册表中的条目（例如需要和 Kubernetes 服务沟通的一组虚拟机服务）。



**WorkloadEntry：**  使运维能够描述单个非 Kubernetes 工作负载的属性，如虚拟机或裸机服务器，因为它被加入网格。一个 WorkloadEntry 必须伴随着一个Istio ServiceEntry，通过适当的标签选择工作负载，并提供MESH_INTERNAL服务的服务定义（主机名、端口属性等）。一个 `ServiceEntry` 对象可以根据服务条目中指定的标签选择器来选择多个工作负载条目以及 Kubernetes pod。









# Demo演示

https://github.com/mosn/mosn-tutorial/blob/master/README_ZH.md



Tutory

https://katacoda.com/mosn/courses/istio



https://www.bilibili.com/video/BV15k4y1r7n8





# Service Mesh目的



**service mesh初衷** 

1.治理与业务逻辑解耦

2.升级成本高

3.SDK版本碎片化

4.跨语言体系治理

5.平滑升级



**Muti Runtime** 

1.业务引入轻量级SDK可扩展几乎无需升级

2.异构多语言容易接入





1.通过sideCar将应用逻辑与基础设置剥离解耦，独立运行 

2.抽象sideCar提供的能力为runtime，面向能力开发屏蔽底层实现





kubectl edit cm istio -n istio-system

```
# Please edit the object below. Lines beginning with a '#' will be ignored,
# and an empty file will abort the edit. If an error occurs while saving this file will be
# reopened with the relevant failures.
#
apiVersion: v1
data:
  mesh: |-
    accessLogFile: /dev/stdout
    defaultConfig:
      discoveryAddress: istiod.istio-system.svc:15012
      proxyMetadata: {}
      tracing:
        zipkin:
          address: zipkin.istio-system:9411
    enablePrometheusMerge: true
    rootNamespace: istio-system
    trustDomain: cluster.local
  meshNetworks: 'networks: {}'
kind: ConfigMap
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","data":{"mesh":"accessLogFile: /dev/stdout\ndefaultConfig:\n  discoveryAddress: istiod.istio-system.svc:15012\n  proxyMetadata: {}\n  tracing:\n    zipkin:\n      address: zipkin.istio-system:9411\nenablePrometheusMerge: true\nrootNamespace: istio-system\ntrustDomain: cluster.local","meshNetworks":"networks: {}"},"kind":"ConfigMap","metadata":{"annotations":{},"labels":{"install.operator.istio.io/owning-resource":"unknown","install.operator.istio.io/owning-resource-namespace":"istio-system","istio.io/rev":"default","operator.istio.io/component":"Pilot","operator.istio.io/managed":"Reconcile","operator.istio.io/version":"1.11.0","release":"istio"},"name":"istio","namespace":"istio-system"}}
  creationTimestamp: "2021-08-17T06:27:39Z"
  labels:
    install.operator.istio.io/owning-resource: unknown
    install.operator.istio.io/owning-resource-namespace: istio-system
    istio.io/rev: default
    operator.istio.io/component: Pilot
    operator.istio.io/managed: Reconcile
    operator.istio.io/version: 1.11.0
    release: istio
  name: istio
  namespace: istio-system
  resourceVersion: "4174"
  uid: 09759c59-8402-4484-a0d8-2b6af25aea79
~                                                      
```



```
istioctl profile dump --config-path components.pilot demo

2021-09-03T06:30:27.803457Z	info	proto: tag has too few fields: "-"

enabled: true

k8s:

 env:

  - name: PILOT_TRACE_SAMPLING

  value: "100"

 resources:

  requests:

   cpu: 10m

   memory: 100Mi
```



部署demo

```
istioctl manifest generate --set profile=demo > demo.yaml

```



查看进程端口是否开启

```
sudo lsof -i tcp:18848
Password:
Sorry, try again.
Password:
Sorry, try again.
Password:
COMMAND   PID      USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME
java    16737 yongliang  423u  IPv6 0xffb401596b7c31e1      0t0  TCP *:18848 (LISTEN)
```



Istio集成注册中心的三种方法

```
https://medium.com/@zhaohuabing/how-to-integrate-your-service-registry-with-istio-34f54b058697
```





# **MCP-OVER-XDS简单示例**

## **部署istio**

istioctl manifest generate --set profile=demo > demo.yaml 修改 istio.istio-system configmap添加以下内容

添加xds configsource

```javascript
    configSources:      - address: xds://172.16.233.1:1109
```

部署istio

```javascript
kubectl apply -f demo.yaml
```

## **实现ads server**

对于原生的envoy-control-plane，使用xds.newserver，利用snapshotcache来实现ads server的方式在istio中不适用，因为envoy-control-plane只能管理原生envoy的xds资源，而mcp-over-xds涉及到istio的crd资源

对于一个adsserver 来说需要实现AggregatedDiscoveryServiceServer接口



```javascript
type AggregatedDiscoveryServiceServer interface {    // This is a gRPC-only API.    StreamAggregatedResources(AggregatedDiscoveryService_StreamAggregatedResourcesServer) error    DeltaAggregatedResources(AggregatedDiscoveryService_DeltaAggregatedResourcesServer) error}
func (m myserver) StreamAggregatedResources(stream d3.AggregatedDiscoveryService_StreamAggregatedResourcesServer) error {    if peerInfo, ok := peer.FromContext(stream.Context()); ok {        log.Println(peerInfo)    }    pushall(stream)    for {        select {        case <-m.psuhc:            pushall(stream)        }    }    return nil}
```

pushall主要了推送对应数据的逻辑,istio会根据TypeUrl进行反解析

```javascript
err = stream.Send(&d3.DiscoveryResponse{        TypeUrl:     "security.istio.io/v1beta1/PeerAuthentication",        VersionInfo: "1",        Nonce:       "",        Resources:   resp,    })
```

这里我们统一为客户端也就是istio推送一个PeerAuthentication策略

```javascript
    pa := v1beta1.PeerAuthentication{        TypeMeta: v1.TypeMeta{            APIVersion: "security.istio.io/v1beta1",            Kind:       "PeerAuthentication",        },        ObjectMeta: v1.ObjectMeta{            Name:      "default",            Namespace: "istio-system",        },        Spec: securityv1beta1.PeerAuthentication{            Mtls: &securityv1beta1.PeerAuthentication_MutualTLS{                Mode: securityv1beta1.PeerAuthentication_MutualTLS_STRICT,            },        },    }
```

## **检查**

•查看配置是否生效 我们访问istiod的debug接口可以看到已经收到了对应的策略

```javascript
curl 172.17.116.27:8080/debug/configz[    {      "kind": "PeerAuthentication",      "apiVersion": "security.istio.io/v1beta1",      "metadata": {        "name": "default",        "namespace": "istio-system",        "resourceVersion": "2020-12-15 06:17:28.774277383 +0000 UTC m=+782.333181911",        "creationTimestamp": null      },      "spec": {        "mtls": {}      }    }  ]
```

•访问服务

部署测试实例

```javascript
kubectl create ns fookubectl apply -f <(istioctl kube-inject -f samples/httpbin/httpbin.yaml) -n fookubectl apply -f <(istioctl kube-inject -f samples/sleep/sleep.yaml) -n fookubectl create ns barkubectl apply -f <(istioctl kube-inject -f samples/httpbin/httpbin.yaml) -n barkubectl apply -f <(istioctl kube-inject -f samples/sleep/sleep.yaml) -n barkubectl create ns legacykubectl apply -f samples/httpbin/httpbin.yaml -n legacykubectl apply -f samples/sleep/sleep.yaml -n legacy
```

访问服务已经无法正常的访问

```javascript
curl httpbin.foo:8000/ipcurl: (56) Recv failure: Connection reset by peer
```

#### **引用链接**

`[1]` MCP-OVER-XDS的实现: *https://github.com/istio/istio/pull/28634* `[2]` 移除了mcp 协议: *https://github.com/istio/istio/pull/28634* `[3]` XDS-OVER-MCP设计: *https://docs.google.com/document/d/1lHjUzDY-4hxElWN7g6pz-_Ws7yIPt62tmX3iGs_uLyI/edit#*





